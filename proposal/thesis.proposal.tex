\documentclass{report}
\usepackage[top=3.5cm, left=3cm, right=3cm]{geometry}
\usepackage{setspace}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{titlesec}

% contents links
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\begin{document}
\titleformat{\chapter}{}{}{0em}{\bf\LARGE}
\pagenumbering{gobble}

% This is the title page.

\centerline{\Huge Guest-Based System Call Introspection}
\vspace{3mm}
\centerline{\Huge with Extended Berkeley Packet Filter}
\vspace{14mm}
\centerline{\large by}
\vspace{15mm}
\centerline{\itshape \large Huzaifa Patel}
\vspace{2cm}
\centerline{\large A thesis proposal submitted to the School of Computer Science in partial fulfillment}
\vspace{2mm}
\centerline{\large of the requirements for the degree of}
\vspace{2cm}
\centerline{\bf \large Bachelor of Computer Science}
\vspace{3cm}
\centerline{\large Under the supervision of Dr. Anil Somayaji}
\vspace{3mm}
\centerline{\large Carleton University}
\vspace{3mm}
\centerline{\large Ottawa, Ontario}
\vspace{3mm}
\centerline{\large September, 2022}
\vspace{3cm}
\centerline{\large \copyright \: 2022 Huzaifa Patel}


% Quote Page.

\newpage
\pagebreak
\hspace{0pt}
\vfill
\centerline{\itshape \large their kindness is masquerade.}
\vspace{3mm}
\centerline{\itshape \large yearning to occupy ones with false pretenses.}
\vspace{3mm}
\centerline{\itshape \large it's used to sedate.}
\vspace{3mm}
\centerline{\itshape \large I promise you'll get this when the sky clears.}
\vfill
\hspace{0pt}
\pagebreak


\begin{spacing}{1.5}









% Abstract.


\newpage
\pagenumbering{roman}
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}















% Acknowledgments.

\newpage

\chapter*{Acknowledgments}
\addcontentsline{toc}{chapter}{Acknowledgments}

{\large I want to express my heartfelt gratitude to my supervisor, Dr. Anil Somayaji for providing me with the opportunity to work on a thesis during the final year of my undergraduate degree. Unlike previous variations of the Computer Science undergraduate degree requirements, completing a thesis is no longer a prerequisite. Therefore, I prostualte it is a great privlidge and honor to be given the opportunity to enroll into a thesis-based course during ones undergraduate studies.}

{\large I did not have prior experience in formal research when I first approached Dr. Somayaji. Despite this shortcoming, it did not stop him from investing his time and resources towards my academic growth. Without his feedback and ideas on my framework implementation and writing of this thesis, as well as his expertise in eBPF, Hypervisors, and Unix based Operating Systems, this thesis would not have been possible.}

{\large I would like to commend PhD student Manuel Andreas from The Technical University of Munich for introducing me to the concept of a Hypervisor. Without him, I would not have approached Dr. Somayaji with the intention of wanting to conduct research on them. His minor action of introducing me to hypervisors had the significant effect of inspiring me to write a thesis on the subject. I also want to thank him for his willingness to endlessly and tirelessly teach, discuss and help me understand the intricacies of hypervisors, the Linux kernel, and the C programming language.} 

{\large I would also like to thank Carleton University's faculty of Computer Science for their efforts in imparting knowledge that has enthraled and inspired me to learn all that I can about Computer Science.}

{\large I would like to extend my appreciation to the various internet communities which have provided the world with invaluable compiled resources on hypervisors, Unix based operating systems, eBPF, the Linux kernel, the C programming language, and Latex, which has helped me tremendously in writing this thesis.}

{\large Finally, I would like to thank my family for their encouragement and support towards my research interests and educational pursuits.}

% define table of contents
\tableofcontents











% Nomenclature

\newpage
\chapter*{Nomenclature}
\addcontentsline{toc}{chapter}{Nomenclature}

\begin{tabular}{lcl}
\large{\bf VM}  & & \large{Virtual Machine} \\
\large{\bf KVM}  & & \large{Kernel-based Virtual Machine} \\
\large{\bf OS}   & & \large{Operating System}        \\
\large{\bf VMI}  & & \large{Virtual Machine Introspection} \\
\large{\bf CPU}  & & \large{Central Processing Unit} \\
\large{\bf VT-x}  & & \large{Intel Virtualization Extension} \\
\large{\bf MSR}  & & \large{Model Specific Register} \\
\large{\bf VMM}  & & \large{Virtual Machine Monitor} \\
\end{tabular}














% Introduction


\newpage
\chapter{Introduction}
\pagenumbering{arabic}


{\large
Cloud computing has been ever-increasing in demand due to its scalability, security
and convenience characteristics. These characteristics can largely be attributed to the
usage of virtualization. Fundamentally, virtualization is a technology that makes it possible for multiple operating systems (OSs) to run concurrently, and in an isolated environment on the same hardware. It makes use of a computer’s physical central processing unit (CPU) to support the software that creates and manages virtual machines (VMs). The software that creates and manages virtual machines has two formal names: (1) hypervisor and (2) virtual machine monitor (VMM). To avoid ambiguity and maintain consistency, we will use the term "hypervisor" throughout this thesis. The operating system running a hypervisor is called the host OS, while the virtual machine that use its resources is known as the guest OS.
\newline
}

{\large 
Kernel-based Virtual Machine (KVM) is a hypervisor, implemented as a Linux kernel module that allows the kernel to function as a hypervisor. It was merged into the mainline Linux kernel in version 2.6.20, which was released on February 5, 2007.[1] KVM requires a CPU with hardware virtualization extensions, such as Intel VT or AMD-V.[2]. In this thesis, we will be focusing on the KVM hypervisor.
\newline
}

{\large
There are two ways a hypervisor can virtualize a machine:

A hypervisor runs Guest OS instructions either directly on the host's CPU, or on the host OS. In both scenarios, 
the goal of a hypervisor is to provide a software-controlled layer that resembles the host hardware. Hypervisors 
can be classified into two types that are dependent on how they to runs Guest OS instructions.
\newline
}

{\large 
(1) Type 1 (bare metal) hypervisors, which runs Guest OS instructions directly on the host’s hardware in order to control
the hardware and monitor the guest OS. Typical examples of such hypervisors include Xen, VMware ESX, and Microsoft Hyper-V.
\newline
}

{\large
(2) Type 2 (hosted) hypervisors, which run within a traditional OS. In other words, a
hosted hypervisor adds a distinct software layer atop the host OS, and the guest OS becomes a third
software layer above the hardware. Well-known examples of type 2 hypervisors include KVM, 
VMware Workstation, VirtualBox, and QEMU.
\newline
}

{\large
Although the preceding type 1 and type 2 hypervisor classification has been widely
accepted, it is not clear it insufficiently differentiates among hypervisors of the same type (e.g., KVM vs. QEMU).


KVM is not a clear case as it could be categorized as either one. The KVM kernel module turns Linux kernel into a type 1 bare-metal hypervisor, while the overall system could be categorized to type 2 because the host OS is still fully functional and the other VM's are standard Linux processes from its perspective.


There-fore, based on how the virtualization gets designed (hardware vs. software) and the guest OS and its 
application code is executed, we can have another type of classification of hypervisors that will be used 
throughout this thesis:
\newline
}

{\large
(1) Native hypervisors that directly push the guest code to execute natively on the
hardware using hardware virtualization.
\newline
}


{\large
(2) Emulation hypervisors that translate each guest instruction for an emulated exe-
cution using software virtualization.
\newline
}

{\large
Examples of native hypervisors include Xen, KVM, VMware ESX, and Microsoft HyperV, and emulation hypervisors include QEMU, Bochs, and the very early versions of
VMware-Workstation and VirtualBox (note that recent VMware-Workstation and VirtualBox are able to execute the guest OS code natively). Since there is no binary code
translation involved, native hypervisor runs much faster than emulation hypervisor.

In this thesis, we will be solely on the KVM VM.








Hardware-assisted




}


{\large


There are 12 projects that use the guest-assisted approach. The pioneer
work, LARES [Payne et al. 2008], inserts hooks in a guest VM and protects its guest com-
ponent by using the hypervisor for memory isolation with the goal of supporting active
monitoring. Unlike passive monitoring, active monitoring requires the interposition of kernel events. As a result, it requires the monitoring code to be executed inside the guest OS, which is why it essentially leads to the solution of inserting certain hooks inside the guest VM. The hooks are used to trigger events that can notify the hypervisor
or redirect execution to an external VM. More specifically, LARES design involves three
components: a guest component, a secure VM, and a hypervisor. The hypervisor helps
to protect the guest VM component by memory isolation and acts as the communica-
tion component between the guest VM and the secure VM. The secure VM is used to
analyze the events and take actions necessary to prevent attacks.


}

\section{Motivation}
https://dl.acm.org/doi/pdf/10.1145/2815400.2815420:
Since hardware-assisted virtualization was introduced to com-
modity x86 servers ten years ago, it has become the common
practice for server deployment [7]. Today, about 75% of x86
server workloads run in virtual machines (VMs) [13]. Virtual-
ization enables the consolidation of multiple VMs on a single
server, thereby reducing hardware and operation costs [14].
Virtualization promises to reduce these costs without sacrific-
ing robustness and security. We contend, however, that this
promise is not fulfilled in practice, because hypervisors—the
software layers that run VMs—are bug-prone. Hypervisor
bugs can cause an operating system (OS) that runs within a
VM to act incorrectly, crash, or become vulnerable to security
exploits [18].
Hypervisor bugs are software bugs, but the damage they
cause is similar to that of hardware bugs. Since hypervisors
virtualize the hardware of VMs, their bugs cause the VMs to
experience that the underlying hardware violates its specifi-
cation. Patching hypervisor bugs is much easier than fixing
the hardware, yet doing so may induce VM downtime and de-
ter cloud customers, as indeed experienced by leading cloud
providers [24, 71].

\subsection{Why Design a New Framework?}
\subsection{Why Out-Of-VM monitor?}
\subsection{Why eBPF?}
\subsection{Why Sequences of System Calls?}

\section{Problem}
\subsection{The Semantic Gap Problem}
\section{Approaching the Problem}

\section{Contributions}

\section{Thesis Organization}

\chapter{Background}
\section{Intel Virtualization Extention (VT-X)}
\section{The Kernel Virtual Machine Hypervisor}
\subsection{Model Specific Registers}
\subsection{VMCS}
\subsection{VM ENTRY Context Switch}
\subsection{VM EXIT Context Switch}
\section{QEMU}
\section{System Calls}
\section{Virtual Machine Introspection}
\section{eBPF}
\section{The Linux Kernel Tracepoint API}
\section{pH-based Sequences of System Call}


\chapter{Related work}

\section{Nitro: Hardware-Based System Call Tracing for Virtual Machines}

\chapter{Implementing Frail}

\section{User Space Component}
\section{Kernel Space Component}
\subsection{Custom Linux Kernel Tracepoint}
\subsection{Kernel Module}
\section{Tracing Processess}
\section{Proof of Tracability of all KVM Guest System Calls}

\chapter{Threat Model of Frail}


\chapter{Future Work}

\chapter{Conclusion}

\chapter{References}

\end{spacing}
\end{document}